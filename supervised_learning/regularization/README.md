# <p align="center">Regularization</p>

## ğŸ¯ Description

This project implements regularization techniques for neural networks to prevent overfitting including L2 regularization for cost functions and gradient descent, dropout for forward and backward propagation and early stopping.

## âš™ï¸ Technologies

python3 (version 3.9)  
tensorflow (version 2.15.0)  
keras (version 2.15.0)  
numpy (version 1.25.2)

## ğŸ“ Clone the repository

```
git clone https://github.com/TonyHolby/holbertonschool-machine_learning.git
cd supervised_learning/regularization/
```

## ğŸ“„ Structure

```
ğŸ“‚ regularization/
â”œâ”€â”€ ğŸ“„ 0-l2_reg_cost.py                     # L2 regularization cost
â”œâ”€â”€ ğŸ“„ 1-l2_reg_gradient_descent.py         # L2 regularization gradient descent
â”œâ”€â”€ ğŸ“„ 2-l2_reg_cost.py                     # L2 regularization cost with tensorflow
â”œâ”€â”€ ğŸ“„ 3-l2_reg_create_layer.py             # L2 regularization layer creation with tensorflow
â”œâ”€â”€ ğŸ“„ 4-dropout_forward_prop.py            # Dropout forward propagation
â”œâ”€â”€ ğŸ“„ 5-dropout_gradient_descent.py        # Dropout gradient descent
â”œâ”€â”€ ğŸ“„ 6-dropout_create_layer.py            # Dropout layer creation with tensorflow
â”œâ”€â”€ ğŸ“„ 7-early_stopping.py                  # Early stopping
â””â”€â”€ ğŸ“„ README.md                            # Project documentation
```

## ğŸ‘¤ Author

Tony NEMOUTHE
